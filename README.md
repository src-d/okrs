# Objectives & Key Results at source{d}

The list and tree below is automatically generated from the issues in this repository, using our [OKR GitHub tool](https://github.com/dennwc/okrs)

-------------

**Progress:** 0/2

### Improve our Monthly Financials Reporting Process

[Source page](https://github.com/src-d/okrs/issues/58)

**Progress:** 0%

* [P0] Create a Monthly Financials Dashboard
* [P0] Refactor existing Excel spreadsheets
* [P0] Successfully incorporate US expenses to Reporting Process

### Vision: Being the leading company for ML on Code

[Source page](https://github.com/src-d/okrs/issues/1)

**Progress:** 0%

* Store the world’s source code ([#5](https://github.com/src-d/okrs/issues/5))
	* [P0] Store all public repositories from GitHub, BitBucket and self-hosted cgit ([#14](https://github.com/src-d/okrs/issues/14))
		* [P0] Stable pipeline with rovers and borges
		* [P0] Get computing and storage production-ready cluster to 60 machines
	* [P1] Keep repositories never more than 30 days outdated ([#15](https://github.com/src-d/okrs/issues/15))
		* [P1] Optimize borges to keep up with all repository updates within 30 days ([#27](https://github.com/src-d/okrs/issues/27))
			* [P0] improve downloading of new repos by 50%
			* [P1] improve update rooted repositories by 50%
			* [P1] increase job throghtput by 30%
			* [P2] decrease timeout errors by 30%
			* [P2] decrease pod restarts by 50%
* Being a better company to work at ([#4](https://github.com/src-d/okrs/issues/4))
	* [P0] Successfully implement best practices for being a remote company ([#40](https://github.com/src-d/okrs/issues/40))
		* [P0] Create a study on employees sentiment
	* [P0] Having a more diverse hiring funnel (increase diversity in terms of gender and race)
	* [P0] Improve instrumentation of the clusters for all teams ([#59](https://github.com/src-d/okrs/issues/59))
		* [P0] Store pipeline cluster logs in a queryable manner ([#45](https://github.com/src-d/okrs/issues/45))
			* [P0] Store logs
			* [P1] Be able to query logs
		* [P0] Support tracing logging
	* [P1] Successfully execute OKRs methodology
	* [P1] Remove technical friction between multiple teams ([#19](https://github.com/src-d/okrs/issues/19))
		* [P0] Introduce monthly empathy sessions or other mechanism where different teams get to try other teams' tools
	* Having a more diverse funnel in terms of gender and race ([#36](https://github.com/src-d/okrs/issues/36))
		* [P1] Identify and solve 2 potential bottlenecks
		* [P1] Bi-weekly tweets mentioning we are hiring and want more women and non-white people in our team
		* [P2] Sourcing through existing communities (eg. women developer communities)
	* Develop a remote on-boarding process ([#34](https://github.com/src-d/okrs/issues/34))
		* [P1] Gain feedback on onboarding from every member who joined after the current implementation of onboarding guide
		* [P1] Have a complete onboarding guide on GitHub
	* Make our interview process more remote friendly ([#33](https://github.com/src-d/okrs/issues/33))
		* [P0] Conduct 2 on-site interviews with an interviewer being remote during the candidate is on-site
		* [P1] Plan detailed steps of the fully-remote interviews to be applied in Q3
		* [P1] Tune the process with what we learned from these interviews ([#55](https://github.com/src-d/okrs/issues/55))
			* [P0] Create research on candidates' sentiment towards on-site and remote interviews
	* Hire for each open role ([#30](https://github.com/src-d/okrs/issues/30))
		* [P0] Attract **relevant** profiles of applicants through developer community
		* [P1] Make one hire for each open role
		* [P1] Increase candidate’s motivation and engagement at every interviewing step
		* [P1] Have a quick process from our side
		* [P1] Gain feedback from the candidates for the hiring process
* Build a go-to-market strategy ([#3](https://github.com/src-d/okrs/issues/3))
	* [P0] Determine which product category (Security & Compliance, Automated Code Review, or QA & Testing)
	* [P0] Determine licensing strategy
	* [P0] Determine go-to-market model
	* [P1] Determine early pricing approach
	* Determine which product category (Security & Compliance, Automated Code Review, or QA & Testing) ([#6](https://github.com/src-d/okrs/issues/6))
		* [P0] Key result x
		* [P1] Deliver structured user research ([#7](https://github.com/src-d/okrs/issues/7))
			* [P0] Define and describe the key use case segments
			* [P0] Map formally the personas for our products
			* [P1] Conduct 15 user research interviews
			* [P1] Conduct quantitative research over the Slack community
* Having successful users of source{d} ([#2](https://github.com/src-d/okrs/issues/2))
	* [P0] Partner with source{d} users ([#46](https://github.com/src-d/okrs/issues/46))
		* [P0] Partner with 4 strategic users (2 in academia / 2 in industry) and provide guides / workshops / samples as they need them
		* [P1] Meet with those users monthly and gather feedback from their experience
		* [P1] Write friction logs / blog posts from their failure / success stories
	* [P0] Users are able to work with PGA ([#11](https://github.com/src-d/okrs/issues/11))
		* [P0] Make engine suitable to run over PGA ([#17](https://github.com/src-d/okrs/issues/17))
			* [P0] Fix the reported errors and do not crash
			* [P1] Report errors with meaning information for tracing the root causes
		* [P0] Make UAST usable without extensive knowledge of Babelfish ([#12](https://github.com/src-d/okrs/issues/12))
			* [P0] Launch higher level UAST abstractions for Babelfish ([#20](https://github.com/src-d/okrs/issues/20))
				* [P0] Higher-level APIs to list simple AST constructs ([#21](https://github.com/src-d/okrs/issues/21))
					* [P0] UAST structure normalization
					* [P0] Port all existing beta language drivers
				* [P1] Higher-level categories for nodes.
				* [P2] Structural pointers.
			* [P0] Update Bblfsh playground ([#56](https://github.com/src-d/okrs/issues/56))
				* [P0] All beta drivers to be supported automatically.
				* [P1] Interactive UAST visualization/manipulation (same as in gitbase playground).
				* [P1] Have reusable components between bblfsh dashboard and gitbase playground.
			* [P0] Have over 2/3 of key users to report feature as satisfactory
		* [P1] Set PGA update policy and perform it ([#41](https://github.com/src-d/okrs/issues/41))
			* [P0] Specify the updates and versioning policy.
			* [P1] Add the regular PGA dataset update job to the full-scale data pipeline.
	* [P0] Launch gitbase and its playground ([#8](https://github.com/src-d/okrs/issues/8))
		* [P0] Make gitbase suitable to run over PGA ([#16](https://github.com/src-d/okrs/issues/16))
			* [P0] Make gitbase better suited for rooted repositories
			* [P0] Make gitbase queries on PGA not crash
			* [P1] Instrument gitbase to be able to trace performance
			* [P1] Improve performance of gitbase over PGA
		* [P0] Design the gitbase playground ([#39](https://github.com/src-d/okrs/issues/39))
			* [P0] Competitive Research
			* [P0] Wireframing
			* [P1] Usability Testing
			* [P1] Working Prototype
			* [P1] User Research Activities & Report
		* [P0] Build gitbase playground ([#51](https://github.com/src-d/okrs/issues/51))
			* [P0] Run gitbase playground locally (with 1 command, for 1 user)
			* [P0] Build web application that allows users to interact with gitbase
			* [P1] Create new interactive visualization of UAST (and apply to both playgrounds)
		* [P0] Launch a hosted version of the playground (>1 concurrent user)
		* [P0] Have over 50 users in the first month after public release
		* [P1] Get over 2/3 of user positive feedback
	* [P0] Launch Gemini application: file-level similarity ([#54](https://github.com/src-d/okrs/issues/54))
		* [P0] Formally launch Gemini as a standalone application of our stack
		* [P0] Run on a single machine, for small number of repositories
		* [P1] Run on Apache Spark cluster, for full PGA
		* [P2] Run on Apache Spark cluster, for full world dataset
	* [P0] Deliver a reference implementation of function-level similarity ([#43](https://github.com/src-d/okrs/issues/43))
		* [P0] XXX Need proper key results for the R&D
		* [P0] Update Code Annotation Tool to support function level ([#57](https://github.com/src-d/okrs/issues/57))
			* [P0] Function-level is supported at CAT for labeling datasets
			* [P1] Reviewer part of CAT uses Feature Extractor REST API from ML
		* [P0] Annotate the dataset of XXX pairs of functions
	* [P0] Define the code review application product ([#9](https://github.com/src-d/okrs/issues/9))
		* [P0] Explore interaction flows with developers ([#47](https://github.com/src-d/okrs/issues/47))
			* [P0] Implement a Go PR review bot able to run multiple static analysis tools, make it available to specific users and gather feedback
			* [P1] Add “do not reinvent the wheel” feature to the bot based on gemini function duplication
			* [P1] Make bot language independent, consider Docker + gRPC based infra
		* [P0] Launch Gemini application: file-level similarity ([#54](https://github.com/src-d/okrs/issues/54))
			* [P0] Formally launch Gemini as a standalone application of our stack
			* [P0] Run on a single machine, for small number of repositories
			* [P1] Run on Apache Spark cluster, for full PGA
			* [P2] Run on Apache Spark cluster, for full world dataset
		* [P0] Research: run Gemini on some repos, generate PR-level report ([#53](https://github.com/src-d/okrs/issues/53))
			* [P0] A DB \w Gemini hashes over some N hand-picked popular repos
			* [P0] A Report on file similarity, for each PR in those repos
		* [P0] Build GitHub bot for PR-level feedback ([#52](https://github.com/src-d/okrs/issues/52))
			* [P0] PoC of the Github bot, \w ability to run different PR-level applications-
			* Design, build it (following regular engineering process) with ability to run it locally
			* Have Gemini integrated there, as a first application
			* Host it on src-d infra
		* [P0] Have at least 2 external OSS projects to adopt it
		* [P1] Get over 2/3 of positive user feedback
	* [P0] Increasing the # of users of the source{d} stack ([#10](https://github.com/src-d/okrs/issues/10))
		* [P0] Make #MLonCode a thing ([#49](https://github.com/src-d/okrs/issues/49))
			* [P0] Identify 20 blog posts / papers on the topic written by others, propose cross-posting to our blog/medium
			* [P1] Identify 10 speakers at conferences talking about #MLonCode, invite them for collaboration / tweet about their talks / partner with them
			* [P2] post 5 times a day in our multiple social media accounts about #MLonCode
			* [P2] create a strategy to manage our online communities (slack, etc) and corresponding online marketing
		* [P0] Make source{d} the face of #MLonCode ([#50](https://github.com/src-d/okrs/issues/50))
			* [P0] Develop half a day workshop on getting started with #MLonCode with source{d} stack (PGA, gitbase?, engine, etc)
			* [P1] Run that workshop at least once at a meetup / conference
			* [P0] Create a new talk on the future of #MLonCode and deliver it at least four times (existing confs and meetups)
			* [P1] Make that workshop and talk available online
			* [P1] Create two demos showing the power of our stack solving a “real problem”
			* [P2] Determine what percentage of time source{d} engineers should spend working on docs/tutorials/talks/etc
		* [P0] Make source{d} the lead of MLonCode research ([#42](https://github.com/src-d/okrs/issues/42))
			* [P0] Create and maintain a research log with TL;DR summaries of research read
			* [P1] Publish 6 ML blog posts in Q2
			* [P2] Speak about ML on >4 relevant conferences
			* [P2] Reach 1,000 cumulative upvotes of new blog posts on Reddit
		* [P0] Enable sharing and publishing MLonCode models ([#44](https://github.com/src-d/okrs/issues/44))
			* [P0] Define and design the product for model sharing (relates to
			* [P1] Conduct user research with all key users (e.g.: key academic groups, users of our stack).
		* [P0] Release updated content for sourced.tech ([#13](https://github.com/src-d/okrs/issues/13))
			* [P0] Create a content strategy plan ([#35](https://github.com/src-d/okrs/issues/35))
				* [P0] Editorial Environment Setup
				* [P0] Customer Journeys
				* [P0] Content Model
				* [P0] Copywriting
				* [P0] Metrics & Evaluation Analytics Setup
				* [P1] Information Architecture
				* [P2] Establish a Content Management Plan
			* [P1] Update brand touchpoints according to content plan
			* [P1] Apply new Visual Style to sourced.tech ([#32](https://github.com/src-d/okrs/issues/32))
				* [P0] Visual Artifacts Study
				* [P1] Research
				* [P1] Chromatic Palete Study
				* [P1] Typography Study
				* [P1] Initial Proposals
				* [P1] Pure css update PR
			* [P1] Publish the CAT case-study development post on Medium ([#38](https://github.com/src-d/okrs/issues/38))
				* [P0] Write a blog post regarding the process, methodologies and collaboration flow between teams on CAT
	* Define DevRel organization ([#48](https://github.com/src-d/okrs/issues/48))
		* [P0] Describe the metrics of devrel success
		* [P0] Set monitoring up for all processes valuable to devrel
		* [P1] Create a dashboard displaying those metrics
		* [P0] Implement kanban processes in DevRel, follow the source{d} Engineering Methodology
		* [P0] Set up biweekly sync-ups with Eiso, Marcelo, Maximo, and Fernanda

